{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd493edf",
   "metadata": {},
   "source": [
    "# Merge data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "209bcff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Datum  Bewoelkung  Temperatur  Windgeschwindigkeit  Wettercode\n",
      "0     2012-01-01         8.0      9.8250                   14        58.0\n",
      "1     2012-01-02         7.0      7.4375                   12         NaN\n",
      "2     2012-01-03         8.0      5.5375                   18        63.0\n",
      "3     2012-01-04         4.0      5.6875                   19        80.0\n",
      "4     2012-01-05         6.0      5.3000                   23        80.0\n",
      "...          ...         ...         ...                  ...         ...\n",
      "2596  2019-07-28         3.0     23.3500                   14         5.0\n",
      "2597  2019-07-29         6.0     25.2500                    7        61.0\n",
      "2598  2019-07-30         7.0     20.7375                    8        61.0\n",
      "2599  2019-07-31         6.0     20.4500                    7        61.0\n",
      "2600  2019-08-01         5.0     21.0625                    9        61.0\n",
      "\n",
      "[2601 rows x 5 columns]\n",
      "           id       Datum  Warengruppe\n",
      "0     1808011  2018-08-01            1\n",
      "1     1808021  2018-08-02            1\n",
      "2     1808031  2018-08-03            1\n",
      "3     1808041  2018-08-04            1\n",
      "4     1808051  2018-08-05            1\n",
      "...       ...         ...          ...\n",
      "1825  1812226  2018-12-22            6\n",
      "1826  1812236  2018-12-23            6\n",
      "1827  1812246  2018-12-24            6\n",
      "1828  1812276  2018-12-27            6\n",
      "1829  1812286  2018-12-28            6\n",
      "\n",
      "[1830 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Import der Umsatz- und der Wetter-Daten\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import statsmodels.api as sm\n",
    "\n",
    "weather = \"/workspaces/bakery_prediction/0_DataPreparation/wetter.csv\"\n",
    "weather = pd.read_csv(weather)\n",
    "print(weather)\n",
    "\n",
    "test = \"/workspaces/bakery_prediction/0_DataPreparation/test.csv\"\n",
    "test = pd.read_csv(test)\n",
    "#print(test)\n",
    "\n",
    "train = \"/workspaces/bakery_prediction/0_DataPreparation/train.csv\"\n",
    "train = pd.read_csv(train)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f1e5485e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2013-07-01\n",
      "2018-07-31\n",
      "           id       Datum  Warengruppe      Umsatz\n",
      "0     1307011  2013-07-01            1  148.828353\n",
      "1     1307021  2013-07-02            1  159.793757\n",
      "2     1307031  2013-07-03            1  111.885594\n",
      "3     1307041  2013-07-04            1  168.864941\n",
      "4     1307051  2013-07-05            1  171.280754\n",
      "...       ...         ...          ...         ...\n",
      "9329  1712216  2017-12-21            6   87.471228\n",
      "9330  1712226  2017-12-22            6   71.911652\n",
      "9331  1712236  2017-12-23            6   84.062223\n",
      "9332  1712246  2017-12-24            6   60.981969\n",
      "9333  1712276  2017-12-27            6   34.972644\n",
      "\n",
      "[9334 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(min(train['Datum']))\n",
    "print(max(train['Datum']))\n",
    "print(train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7c18170c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-08-01\n",
      "2019-07-30\n",
      "           id       Datum  Warengruppe\n",
      "0     1808011  2018-08-01            1\n",
      "1     1808021  2018-08-02            1\n",
      "2     1808031  2018-08-03            1\n",
      "3     1808041  2018-08-04            1\n",
      "4     1808051  2018-08-05            1\n",
      "...       ...         ...          ...\n",
      "1825  1812226  2018-12-22            6\n",
      "1826  1812236  2018-12-23            6\n",
      "1827  1812246  2018-12-24            6\n",
      "1828  1812276  2018-12-27            6\n",
      "1829  1812286  2018-12-28            6\n",
      "\n",
      "[1830 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(min(test['Datum']))\n",
    "print(max(test['Datum']))\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6606b3e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             id       Datum  Warengruppe  Windgeschwindigkeit\n",
      "0           NaN  2012-01-01          NaN                 14.0\n",
      "1           NaN  2012-01-02          NaN                 12.0\n",
      "2           NaN  2012-01-03          NaN                 18.0\n",
      "3           NaN  2012-01-04          NaN                 19.0\n",
      "4           NaN  2012-01-05          NaN                 23.0\n",
      "...         ...         ...          ...                  ...\n",
      "4084  1907303.0  2019-07-30          3.0                  8.0\n",
      "4085  1907304.0  2019-07-30          4.0                  8.0\n",
      "4086  1907305.0  2019-07-30          5.0                  8.0\n",
      "4087        NaN  2019-07-31          NaN                  7.0\n",
      "4088        NaN  2019-08-01          NaN                  9.0\n",
      "\n",
      "[4089 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# merge weather data with train and test data\n",
    "train_data = pd.merge(train,weather, how='outer')\n",
    "Wind = weather[[\"Datum\",\"Windgeschwindigkeit\"]]\n",
    "test_data =  pd.merge(test,Wind, how='outer')\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c72bc6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define date thresholds\n",
    "train_begin_date = \"2013-07-01\"\n",
    "train_end_date = \"2017-07-31\"\n",
    "\n",
    "validation_begin_date =\"2017-08-01\"\n",
    "validation_end_date =\"2018-07-31\"\n",
    "\n",
    "test_begin_date = \"2018-08-01\"\n",
    "test_end_date = \"2019-07-31\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2e2624bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                     10\n",
      "Datum                   0\n",
      "Warengruppe            10\n",
      "Windgeschwindigkeit    65\n",
      "dtype: int64\n",
      "1840\n"
     ]
    }
   ],
   "source": [
    "# trim test data to relevant dates and drop rows with missing values\n",
    "test_data = test_data[(test_data[\"Datum\"] >= test_begin_date) & (test_data[\"Datum\"] <= test_end_date)]\n",
    "#test_data = test_data.dropna(how='any')\n",
    "#test_data = test\n",
    "print(test_data.isna().sum())\n",
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5df4d84b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                     0\n",
      "Datum                  0\n",
      "Warengruppe            0\n",
      "Umsatz                 0\n",
      "Bewoelkung             0\n",
      "Temperatur             0\n",
      "Windgeschwindigkeit    0\n",
      "Wettercode             0\n",
      "dtype: int64\n",
      "             id       Datum  Warengruppe      Umsatz  Bewoelkung  Temperatur  \\\n",
      "394   1307011.0  2013-07-01          1.0  148.828353         6.0     17.8375   \n",
      "395   1307012.0  2013-07-01          2.0  535.856285         6.0     17.8375   \n",
      "396   1307013.0  2013-07-01          3.0  201.198426         6.0     17.8375   \n",
      "397   1307014.0  2013-07-01          4.0   65.890169         6.0     17.8375   \n",
      "398   1307015.0  2013-07-01          5.0  317.475875         6.0     17.8375   \n",
      "...         ...         ...          ...         ...         ...         ...   \n",
      "7907  1707301.0  2017-07-30          1.0   65.453279         5.0     24.0000   \n",
      "7908  1707302.0  2017-07-30          2.0  605.805099         5.0     24.0000   \n",
      "7909  1707303.0  2017-07-30          3.0  322.250156         5.0     24.0000   \n",
      "7910  1707304.0  2017-07-30          4.0  150.306407         5.0     24.0000   \n",
      "7911  1707305.0  2017-07-30          5.0  294.303759         5.0     24.0000   \n",
      "\n",
      "      Windgeschwindigkeit  Wettercode  \n",
      "394                  15.0        20.0  \n",
      "395                  15.0        20.0  \n",
      "396                  15.0        20.0  \n",
      "397                  15.0        20.0  \n",
      "398                  15.0        20.0  \n",
      "...                   ...         ...  \n",
      "7907                 11.0        61.0  \n",
      "7908                 11.0        61.0  \n",
      "7909                 11.0        61.0  \n",
      "7910                 11.0        61.0  \n",
      "7911                 11.0        61.0  \n",
      "\n",
      "[5399 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "# trim training data to relevant dates and drop rows with missing values\n",
    "train_data = train_data[(train_data[\"Datum\"] >= train_begin_date) & (train_data[\"Datum\"] <= train_end_date)]\n",
    "train_data = train_data.dropna(how='any')\n",
    "print(train_data.isna().sum())\n",
    "print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5f857462",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_data[[\"Warengruppe\"]]\n",
    "X_train = sm.add_constant(X_train)\n",
    "Y_train = train_data[\"Umsatz\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "70307bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                 Umsatz   R-squared:                       0.003\n",
      "Model:                            OLS   Adj. R-squared:                  0.003\n",
      "Method:                 Least Squares   F-statistic:                     17.68\n",
      "Date:                Sun, 14 Dec 2025   Prob (F-statistic):           2.66e-05\n",
      "Time:                        15:20:35   Log-Likelihood:                -34472.\n",
      "No. Observations:                5399   AIC:                         6.895e+04\n",
      "Df Residuals:                    5397   BIC:                         6.896e+04\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===============================================================================\n",
      "                  coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------\n",
      "const         219.0414      4.484     48.854      0.000     210.252     227.831\n",
      "Warengruppe    -5.4654      1.300     -4.204      0.000      -8.014      -2.917\n",
      "==============================================================================\n",
      "Omnibus:                     2605.109   Durbin-Watson:                   2.434\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            29811.110\n",
      "Skew:                           2.020   Prob(JB):                         0.00\n",
      "Kurtosis:                      13.780   Cond. No.                         8.47\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "model = sm.OLS(Y_train,X_train).fit()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c46a5723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Warengruppe  Windgeschwindigkeit\n",
      "2248          1.0                 10.0\n",
      "2249          2.0                 10.0\n",
      "2250          3.0                 10.0\n",
      "2251          4.0                 10.0\n",
      "2252          5.0                 10.0\n",
      "...           ...                  ...\n",
      "4083          2.0                  8.0\n",
      "4084          3.0                  8.0\n",
      "4085          4.0                  8.0\n",
      "4086          5.0                  8.0\n",
      "4087          NaN                  7.0\n",
      "\n",
      "[1840 rows x 2 columns]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (1840,3) and (2,) not aligned: 3 (dim 1) != 2 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[90]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(X_test)\n\u001b[32m      5\u001b[39m X_test = sm.add_constant(X_test)  \u001b[38;5;66;03m# Add constant to test set for predictions\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m predictions = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(predictions))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/statsmodels/base/model.py:1174\u001b[39m, in \u001b[36mResults.predict\u001b[39m\u001b[34m(self, exog, transform, *args, **kwargs)\u001b[39m\n\u001b[32m   1127\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1128\u001b[39m \u001b[33;03mCall self.model.predict with self.params as the first argument.\u001b[39;00m\n\u001b[32m   1129\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1169\u001b[39m \u001b[33;03mreturned prediction.\u001b[39;00m\n\u001b[32m   1170\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1171\u001b[39m exog, exog_index = \u001b[38;5;28mself\u001b[39m._transform_predict_exog(exog,\n\u001b[32m   1172\u001b[39m                                                 transform=transform)\n\u001b[32m-> \u001b[39m\u001b[32m1174\u001b[39m predict_results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1175\u001b[39m \u001b[43m                                     \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1177\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m exog_index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(predict_results,\n\u001b[32m   1178\u001b[39m                                           \u001b[33m'\u001b[39m\u001b[33mpredicted_values\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m   1179\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m predict_results.ndim == \u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:409\u001b[39m, in \u001b[36mRegressionModel.predict\u001b[39m\u001b[34m(self, params, exog)\u001b[39m\n\u001b[32m    406\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m exog \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    407\u001b[39m     exog = \u001b[38;5;28mself\u001b[39m.exog\n\u001b[32m--> \u001b[39m\u001b[32m409\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mValueError\u001b[39m: shapes (1840,3) and (2,) not aligned: 3 (dim 1) != 2 (dim 0)"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set\n",
    "#print(test_data)\n",
    "X_test = test_data[[\"Warengruppe\",\"Windgeschwindigkeit\"]]\n",
    "print(X_test)\n",
    "X_test = sm.add_constant(X_test)  # Add constant to test set for predictions\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "print(len(predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c923477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1830\n",
      "id             0\n",
      "Datum          0\n",
      "Warengruppe    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "pred_df = pd.DataFrame({\n",
    "    'Umsatz': predictions\n",
    "}, index=X_test.index)\n",
    "X_test2 = test_data[[\"id\"]]\n",
    "# Merge with original DataFrame\n",
    "df_with_preds = X_test2.join(pred_df)\n",
    "#print(X_test2)\n",
    "print(len(df_with_preds))\n",
    "print(test_data.isna().sum())\n",
    "# Save to CSV\n",
    "write_path = \"/workspaces/bakery_prediction/1_DatasetCharacteristics/predictions.csv\"\n",
    "df_with_preds.to_csv(write_path, index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d4ec46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Y_test = test_data[\"Umsatz\"]\n",
    "\n",
    "# Calculate Mean Absolute Percentage Error (MAPE) for error evaluation\n",
    "#mape = (abs((Y_test - predictions) / Y_test).mean()) * 100\n",
    "#print(f\"Mean Absolute Percentage Error (MAPE): {mape:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
