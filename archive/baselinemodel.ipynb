{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81c93bad",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Bakery Sales Prediction with Multiple Linear Regression\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# Import necessary libraries\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "# Bakery Sales Prediction with Multiple Linear Regression\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# =============================================================================\n",
    "# 1. LOAD DATA\n",
    "# =============================================================================\n",
    "print(\"=\" * 80)\n",
    "print(\"LOADING DATA\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Load datasets (update these paths to your actual file locations)\n",
    "weather_path = \"/workspaces/bakery_prediction/0_DataPreparation/wetter.csv\"\n",
    "test_path = \"/workspaces/bakery_prediction/0_DataPreparation/test.csv\"\n",
    "train_path = \"/workspaces/bakery_prediction/0_DataPreparation/train.csv\"\n",
    "\n",
    "weather = pd.read_csv(weather_path)\n",
    "test = pd.read_csv(test_path)\n",
    "train = pd.read_csv(train_path)\n",
    "\n",
    "print(f\"Weather data shape: {weather.shape}\")\n",
    "print(f\"Train data shape: {train.shape}\")\n",
    "print(f\"Test data shape: {test.shape}\")\n",
    "\n",
    "# Display date ranges\n",
    "print(f\"\\nTraining data date range: {min(train['Datum'])} to {max(train['Datum'])}\")\n",
    "print(f\"Test data date range: {min(test['Datum'])} to {max(test['Datum'])}\")\n",
    "\n",
    "# =============================================================================\n",
    "# 2. MERGE DATASETS\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"MERGING DATASETS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Merge weather data with train data (using all weather columns)\n",
    "train_data = pd.merge(train, weather, on='Datum', how='left')\n",
    "print(f\"Merged training data shape: {train_data.shape}\")\n",
    "\n",
    "# Merge weather data with test data (using all weather columns or specific ones)\n",
    "test_data = pd.merge(test, weather, on='Datum', how='left')\n",
    "print(f\"Merged test data shape: {test_data.shape}\")\n",
    "\n",
    "# =============================================================================\n",
    "# 3. FILTER DATA BY DATE RANGES\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"FILTERING DATA BY DATE RANGES\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Define date thresholds\n",
    "train_begin_date = \"2013-07-01\"\n",
    "train_end_date = \"2017-07-31\"\n",
    "validation_begin_date = \"2017-08-01\"\n",
    "validation_end_date = \"2018-07-31\"\n",
    "test_begin_date = \"2018-08-01\"\n",
    "test_end_date = \"2019-07-31\"\n",
    "\n",
    "# Filter training data\n",
    "train_data = train_data[\n",
    "    (train_data[\"Datum\"] >= train_begin_date) & \n",
    "    (train_data[\"Datum\"] <= train_end_date)\n",
    "]\n",
    "\n",
    "# Filter test data\n",
    "test_data = test_data[\n",
    "    (test_data[\"Datum\"] >= test_begin_date) & \n",
    "    (test_data[\"Datum\"] <= test_end_date)\n",
    "]\n",
    "\n",
    "print(f\"Filtered training data shape: {train_data.shape}\")\n",
    "print(f\"Filtered test data shape: {test_data.shape}\")\n",
    "\n",
    "# =============================================================================\n",
    "# 4. HANDLE MISSING VALUES\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"HANDLING MISSING VALUES\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\nMissing values in training data BEFORE cleaning:\")\n",
    "print(train_data.isna().sum())\n",
    "\n",
    "print(\"\\nMissing values in test data BEFORE cleaning:\")\n",
    "print(test_data.isna().sum())\n",
    "\n",
    "# Drop rows with missing values in training data\n",
    "train_data = train_data.dropna(how='any')\n",
    "\n",
    "print(f\"\\nTraining data shape after dropping NaN: {train_data.shape}\")\n",
    "\n",
    "# For test data, you might want to fill missing values instead of dropping\n",
    "# since you need predictions for all test rows\n",
    "# Option 1: Fill with mean\n",
    "test_data['Windgeschwindigkeit'] = test_data['Windgeschwindigkeit'].fillna(\n",
    "    test_data['Windgeschwindigkeit'].mean()\n",
    ")\n",
    "\n",
    "# If there are other columns with missing values, handle them too\n",
    "# For example, fill numeric columns with mean\n",
    "numeric_cols = test_data.select_dtypes(include=[np.number]).columns\n",
    "for col in numeric_cols:\n",
    "    if test_data[col].isna().sum() > 0:\n",
    "        test_data[col] = test_data[col].fillna(test_data[col].mean())\n",
    "\n",
    "print(\"\\nMissing values in test data AFTER cleaning:\")\n",
    "print(test_data.isna().sum())\n",
    "\n",
    "# =============================================================================\n",
    "# 5. PREPARE FEATURES AND TARGET\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"PREPARING FEATURES FOR MODEL\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Define independent variables (features) - NOW INCLUDING BOTH VARIABLES\n",
    "X_train = train_data[[\"Warengruppe\", \"Windgeschwindigkeit\"]]\n",
    "y_train = train_data[\"Umsatz\"]\n",
    "\n",
    "print(f\"Training features shape: {X_train.shape}\")\n",
    "print(f\"Training target shape: {y_train.shape}\")\n",
    "print(f\"\\nFeature statistics:\")\n",
    "print(X_train.describe())\n",
    "\n",
    "# Add constant term for intercept\n",
    "X_train_with_const = sm.add_constant(X_train)\n",
    "\n",
    "# =============================================================================\n",
    "# 6. TRAIN THE MODEL\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"TRAINING MULTIPLE LINEAR REGRESSION MODEL\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Train OLS model with BOTH independent variables\n",
    "model = sm.OLS(y_train, X_train_with_const).fit()\n",
    "\n",
    "# Display model summary\n",
    "print(model.summary())\n",
    "\n",
    "# Extract coefficients\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"MODEL COEFFICIENTS\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Intercept: {model.params['const']:.4f}\")\n",
    "print(f\"Coefficient for Warengruppe: {model.params['Warengruppe']:.4f}\")\n",
    "print(f\"Coefficient for Windgeschwindigkeit: {model.params['Windgeschwindigkeit']:.4f}\")\n",
    "\n",
    "print(f\"\\nRegression Equation:\")\n",
    "print(f\"Umsatz = {model.params['const']:.4f} + \"\n",
    "      f\"{model.params['Warengruppe']:.4f}*Warengruppe + \"\n",
    "      f\"{model.params['Windgeschwindigkeit']:.4f}*Windgeschwindigkeit\")\n",
    "\n",
    "# =============================================================================\n",
    "# 7. MAKE PREDICTIONS ON TRAINING DATA (for evaluation)\n",
    "# =============================================================================\n",
    "train_predictions = model.predict(X_train_with_const)\n",
    "\n",
    "# Calculate training metrics\n",
    "train_mae = mean_absolute_error(y_train, train_predictions)\n",
    "train_rmse = np.sqrt(mean_squared_error(y_train, train_predictions))\n",
    "train_r2 = r2_score(y_train, train_predictions)\n",
    "train_mape = (abs((y_train - train_predictions) / y_train).mean()) * 100\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"TRAINING SET PERFORMANCE\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"R² Score: {train_r2:.4f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {train_mae:.2f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {train_rmse:.2f}\")\n",
    "print(f\"Mean Absolute Percentage Error (MAPE): {train_mape:.2f}%\")\n",
    "\n",
    "# =============================================================================\n",
    "# 8. MAKE PREDICTIONS ON TEST DATA\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"MAKING PREDICTIONS ON TEST DATA\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Prepare test features - SAME FEATURES AS TRAINING\n",
    "X_test = test_data[[\"Warengruppe\", \"Windgeschwindigkeit\"]]\n",
    "X_test_with_const = sm.add_constant(X_test)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(X_test_with_const)\n",
    "\n",
    "print(f\"Number of predictions: {len(predictions)}\")\n",
    "print(f\"Sample predictions (first 10):\")\n",
    "print(predictions.head(10))\n",
    "\n",
    "# =============================================================================\n",
    "# 9. CREATE SUBMISSION FILE\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"CREATING SUBMISSION FILE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Create predictions dataframe\n",
    "pred_df = pd.DataFrame({\n",
    "    'id': test_data['id'],\n",
    "    'Umsatz': predictions\n",
    "})\n",
    "\n",
    "print(f\"Prediction dataframe shape: {pred_df.shape}\")\n",
    "print(f\"\\nFirst 10 predictions:\")\n",
    "print(pred_df.head(10))\n",
    "\n",
    "# Save to CSV\n",
    "output_path = \"/workspaces/bakery_prediction/1_DatasetCharacteristics/predictions.csv\"\n",
    "pred_df.to_csv(output_path, index=False)\n",
    "print(f\"\\nPredictions saved to: {output_path}\")\n",
    "\n",
    "# =============================================================================\n",
    "# 10. VISUALIZATION\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"CREATING VISUALIZATIONS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "\n",
    "# Plot 1: Actual vs Predicted (Training)\n",
    "axes[0, 0].scatter(y_train, train_predictions, alpha=0.5)\n",
    "axes[0, 0].plot([y_train.min(), y_train.max()], \n",
    "                [y_train.min(), y_train.max()], 'r--', lw=2)\n",
    "axes[0, 0].set_xlabel('Actual Umsatz')\n",
    "axes[0, 0].set_ylabel('Predicted Umsatz')\n",
    "axes[0, 0].set_title(f'Training: Actual vs Predicted\\nR² = {train_r2:.4f}')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Residuals\n",
    "residuals = y_train - train_predictions\n",
    "axes[0, 1].scatter(train_predictions, residuals, alpha=0.5)\n",
    "axes[0, 1].axhline(y=0, color='r', linestyle='--', lw=2)\n",
    "axes[0, 1].set_xlabel('Predicted Umsatz')\n",
    "axes[0, 1].set_ylabel('Residuals')\n",
    "axes[0, 1].set_title('Residual Plot')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Residual Distribution\n",
    "axes[0, 2].hist(residuals, bins=50, alpha=0.7, edgecolor='black')\n",
    "axes[0, 2].set_xlabel('Residuals')\n",
    "axes[0, 2].set_ylabel('Frequency')\n",
    "axes[0, 2].set_title('Distribution of Residuals')\n",
    "axes[0, 2].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: Umsatz vs Warengruppe\n",
    "axes[1, 0].scatter(train_data['Warengruppe'], y_train, alpha=0.3)\n",
    "axes[1, 0].set_xlabel('Warengruppe')\n",
    "axes[1, 0].set_ylabel('Umsatz')\n",
    "axes[1, 0].set_title('Umsatz vs Warengruppe')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 5: Umsatz vs Windgeschwindigkeit\n",
    "axes[1, 1].scatter(train_data['Windgeschwindigkeit'], y_train, alpha=0.3)\n",
    "axes[1, 1].set_xlabel('Windgeschwindigkeit')\n",
    "axes[1, 1].set_ylabel('Umsatz')\n",
    "axes[1, 1].set_title('Umsatz vs Windgeschwindigkeit')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 6: Q-Q Plot for normality of residuals\n",
    "stats.probplot(residuals, dist=\"norm\", plot=axes[1, 2])\n",
    "axes[1, 2].set_title('Q-Q Plot (Normality of Residuals)')\n",
    "axes[1, 2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "viz_path = \"/workspaces/bakery_prediction/1_DatasetCharacteristics/model_diagnostics.png\"\n",
    "plt.savefig(viz_path, dpi=300, bbox_inches='tight')\n",
    "print(f\"Visualizations saved to: {viz_path}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ANALYSIS COMPLETE!\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9fa452",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
